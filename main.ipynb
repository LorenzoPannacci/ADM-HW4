{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook by:\n",
    "\n",
    "* Lorenzo Pannacci 1948926\n",
    "* ADD YOUR NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# LIBRARIES DOWNLOAD #\n",
    "######################\n",
    "\n",
    "install_packages = False\n",
    "if install_packages:\n",
    "    %pip install numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# LIBRARIES IMPORT #\n",
    "####################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# GLOBAL PARAMETERS #\n",
    "#####################\n",
    "\n",
    "dataset_path = r\"data/vodclickstream_uk_movies_03.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recommendation sytem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a recommendation system is critical for businesses and digital platforms that want to thrive in today's competitive environment. These systems use data-driven personalization to tailor content, products, and services to individual user preferences. The latter improves user engagement, satisfaction, retention, and revenue through increased sales and cross-selling opportunities. In this section, you will attempt to implement a recommendation system by identifying similar users' preferences and recommending movies they watch to the study user. \n",
    "\n",
    "To be more specific, you will implement your version of the [**LSH algorithm**](https://www.learndatasci.com/tutorials/building-recommendation-engine-locality-sensitive-hashing-lsh-python/), which will take as input the user's preferred genre of movies, find the most similar users to this user, and recommend the most watched movies by those who are more similar to the user. \n",
    "\n",
    "__Data__: The data you will be working with can be found [here](https://www.kaggle.com/datasets/vodclickstream/netflix-audience-behaviour-uk-movies).\n",
    "\n",
    "Looking at the data, you can see that there is data available for each user for the movies the user <ins>clicked on</ins>. Gather the __title and genre__ of the __maximum top 10 movies__ that each user clicked on regarding the __number of clicks__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Minhash Signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the movie genre and user_ids, try to implement your min-hash signatures so that users with similar interests in a genre appear in the same bucket. \n",
    "\n",
    "__Important note:__ You must write your minhash function from scratch.  You are not permitted to use any already implemented hash functions.  Read the class materials and, if necessary, conduct an internet search.  The description of hash functions in the [book](http://infolab.stanford.edu/~ullman/mmds/ch3n.pdf) may be helpful as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Locality-Sensitive Hashing (LSH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your buckets are ready, it's time to ask a few queries. We will provide you with some user_ids and ask you to recommend at __most five movies__ to the user to watch based on the movies clicked by similar users. \n",
    "\n",
    "To recommend at most five movies given a user_id, use the following procedure: \n",
    "\n",
    "1. Identify the <ins>two most similar</ins> users to this user.\n",
    "2. If these two users have any movies __in common__, recommend those movies based on the total number of clicks by these users.\n",
    "3. If there are __no more common__ movies, try to propose the most clicked movies by the __most similar user first__, followed by the other user. \n",
    "\n",
    "__Note:__ At the end of the process, we expect to see at most five movies recommended to the user.\n",
    "\n",
    "__Example:__ assume you've identified user __A__ and __B__ as the most similar users to a single user, and we have the following records on these users: \n",
    "\n",
    "- User A with 80% similarity\n",
    "- User B with 50% similarity\n",
    "  \n",
    "|user|movie title|#clicks|\n",
    "|---|---|---|\n",
    "|A|Wild Child|20|\n",
    "|A|Innocence|10|\n",
    "|A|Coin Heist|2|\n",
    "|B|Innocence|30|\n",
    "|B|Coin Heist|15|\n",
    "|B|Before I Fall|30|\n",
    "|B|Beyond Skyline|8|\n",
    "|B|The Amazing Spider-Man|5|\n",
    "\n",
    "- __Recommended movies__ in order:\n",
    "    - Innocence\n",
    "    - Coin Heist\n",
    "    - Wild Child\n",
    "    - Before I Fall\n",
    "    - Beyond Skyline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grouping Users together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will deal with clustering algorithms that will provide groups of Netflix users that are similar among them.\n",
    "\n",
    "To solve this task, you must accomplish the following stages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Getting your data + feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  Access to the data found in [this dataset](https://www.kaggle.com/datasets/vodclickstream/netflix-audience-behaviour-uk-movies)\n",
    "\n",
    "2)  Sometimes, the features (variables, fields) are not given in a dataset but can be created from it; this is known as *feature engineering*. For example, the original dataset has several clicks done by the same user, so grouping data by user_id will allow you to create new features **for each** user:\n",
    "\n",
    "    a)  Favorite genre (i.e., the genre on which the user spent the most time)\n",
    "\n",
    "    b)  Average click duration\n",
    "\n",
    "    c)  Time of the day (Morning/Afternoon/Night) when the user spends the most time on the platform (the time spent is tracked through the duration of the clicks)\n",
    "\n",
    "    d)  Is the user an old movie lover, or is he into more recent stuff (content released after 2010)?\n",
    "\n",
    "    e)  Average time spent a day by the user (considering only the days he logs in)\n",
    "\n",
    "So, in the end, you should have for each user_id five features.\n",
    "\n",
    "3)  Consider at least 10 additional features that can be generated for each user_id (you can use chatGPT or other LLM tools for suggesting features to create). Describe each of them and add them to the previous dataset you made (the one with five features). In the end, you should have for each user at least 15 features (5 recommended + 10 suggested by you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We start by exploring our data and convert it in a more usable form. The dataset is light, we don't have to worry about dividing it into chunks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58773</td>\n",
       "      <td>2017-01-01 01:15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angus, Thongs and Perfect Snogging</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>26bd5987e8</td>\n",
       "      <td>1dea19f6fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58774</td>\n",
       "      <td>2017-01-01 13:56:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Curse of Sleeping Beauty</td>\n",
       "      <td>Fantasy, Horror, Mystery, Thriller</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>f26ed2675e</td>\n",
       "      <td>544dcbc510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58775</td>\n",
       "      <td>2017-01-01 15:17:47</td>\n",
       "      <td>10530.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>7cbcc791bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58776</td>\n",
       "      <td>2017-01-01 16:04:13</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Vendetta</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>c74aec7673</td>\n",
       "      <td>ebf43c36b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58777</td>\n",
       "      <td>2017-01-01 19:16:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The SpongeBob SquarePants Movie</td>\n",
       "      <td>Animation, Action, Adventure, Comedy, Family, ...</td>\n",
       "      <td>2004-11-19</td>\n",
       "      <td>a80d6fc2aa</td>\n",
       "      <td>a57c992287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671731</th>\n",
       "      <td>730504</td>\n",
       "      <td>2019-06-30 21:37:08</td>\n",
       "      <td>851.0</td>\n",
       "      <td>Oprah Presents When They See Us Now</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>43cd23f30f</td>\n",
       "      <td>57501964fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671732</th>\n",
       "      <td>730505</td>\n",
       "      <td>2019-06-30 21:49:34</td>\n",
       "      <td>91157.0</td>\n",
       "      <td>HALO Legends</td>\n",
       "      <td>Animation, Action, Adventure, Family, Sci-Fi</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>febf42d55f</td>\n",
       "      <td>d4fcb079ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671733</th>\n",
       "      <td>730506</td>\n",
       "      <td>2019-06-30 22:00:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pacific Rim</td>\n",
       "      <td>Action, Adventure, Sci-Fi</td>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>7b15e5ada1</td>\n",
       "      <td>4a14a2cd5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671734</th>\n",
       "      <td>730507</td>\n",
       "      <td>2019-06-30 22:04:23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ReMastered: The Two Killings of Sam Cooke</td>\n",
       "      <td>Documentary, Music</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>52d49c515a</td>\n",
       "      <td>0b8163ea4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671735</th>\n",
       "      <td>730508</td>\n",
       "      <td>2019-06-30 22:35:24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chopsticks</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>0be62aac8b</td>\n",
       "      <td>5e5755d816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671736 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0             datetime  duration  \\\n",
       "0            58773  2017-01-01 01:15:09       0.0   \n",
       "1            58774  2017-01-01 13:56:02       0.0   \n",
       "2            58775  2017-01-01 15:17:47   10530.0   \n",
       "3            58776  2017-01-01 16:04:13      49.0   \n",
       "4            58777  2017-01-01 19:16:37       0.0   \n",
       "...            ...                  ...       ...   \n",
       "671731      730504  2019-06-30 21:37:08     851.0   \n",
       "671732      730505  2019-06-30 21:49:34   91157.0   \n",
       "671733      730506  2019-06-30 22:00:44       0.0   \n",
       "671734      730507  2019-06-30 22:04:23       0.0   \n",
       "671735      730508  2019-06-30 22:35:24       0.0   \n",
       "\n",
       "                                            title  \\\n",
       "0              Angus, Thongs and Perfect Snogging   \n",
       "1                    The Curse of Sleeping Beauty   \n",
       "2                               London Has Fallen   \n",
       "3                                        Vendetta   \n",
       "4                 The SpongeBob SquarePants Movie   \n",
       "...                                           ...   \n",
       "671731        Oprah Presents When They See Us Now   \n",
       "671732                               HALO Legends   \n",
       "671733                                Pacific Rim   \n",
       "671734  ReMastered: The Two Killings of Sam Cooke   \n",
       "671735                                 Chopsticks   \n",
       "\n",
       "                                                   genres release_date  \\\n",
       "0                                  Comedy, Drama, Romance   2008-07-25   \n",
       "1                      Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
       "2                                        Action, Thriller   2016-03-04   \n",
       "3                                           Action, Drama   2015-06-12   \n",
       "4       Animation, Action, Adventure, Comedy, Family, ...   2004-11-19   \n",
       "...                                                   ...          ...   \n",
       "671731                                          Talk-Show   2019-06-12   \n",
       "671732       Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
       "671733                          Action, Adventure, Sci-Fi   2013-07-12   \n",
       "671734                                 Documentary, Music   2019-02-08   \n",
       "671735                                      Comedy, Drama   2019-05-31   \n",
       "\n",
       "          movie_id     user_id  \n",
       "0       26bd5987e8  1dea19f6fe  \n",
       "1       f26ed2675e  544dcbc510  \n",
       "2       f77e500e7a  7cbcc791bf  \n",
       "3       c74aec7673  ebf43c36b6  \n",
       "4       a80d6fc2aa  a57c992287  \n",
       "...            ...         ...  \n",
       "671731  43cd23f30f  57501964fd  \n",
       "671732  febf42d55f  d4fcb079ba  \n",
       "671733  7b15e5ada1  4a14a2cd5a  \n",
       "671734  52d49c515a  0b8163ea4b  \n",
       "671735  0be62aac8b  5e5755d816  \n",
       "\n",
       "[671736 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset from the .json file to a pandas dataframe\n",
    "original_dataset = pd.read_csv(dataset_path)\n",
    "original_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 671736 entries, 0 to 671735\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Unnamed: 0    671736 non-null  int64  \n",
      " 1   datetime      671736 non-null  object \n",
      " 2   duration      671736 non-null  float64\n",
      " 3   title         671736 non-null  object \n",
      " 4   genres        671736 non-null  object \n",
      " 5   release_date  671736 non-null  object \n",
      " 6   movie_id      671736 non-null  object \n",
      " 7   user_id       671736 non-null  object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 41.0+ MB\n"
     ]
    }
   ],
   "source": [
    "original_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The first thing we notice is the presence of a column called `Unnamed: 0` that has an incremental value. We can discard it and uses our index that starts from 0:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 01:15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angus, Thongs and Perfect Snogging</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>26bd5987e8</td>\n",
       "      <td>1dea19f6fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 13:56:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Curse of Sleeping Beauty</td>\n",
       "      <td>Fantasy, Horror, Mystery, Thriller</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>f26ed2675e</td>\n",
       "      <td>544dcbc510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 15:17:47</td>\n",
       "      <td>10530.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>7cbcc791bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 16:04:13</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Vendetta</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>c74aec7673</td>\n",
       "      <td>ebf43c36b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 19:16:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The SpongeBob SquarePants Movie</td>\n",
       "      <td>Animation, Action, Adventure, Comedy, Family, ...</td>\n",
       "      <td>2004-11-19</td>\n",
       "      <td>a80d6fc2aa</td>\n",
       "      <td>a57c992287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671731</th>\n",
       "      <td>2019-06-30 21:37:08</td>\n",
       "      <td>851.0</td>\n",
       "      <td>Oprah Presents When They See Us Now</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>43cd23f30f</td>\n",
       "      <td>57501964fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671732</th>\n",
       "      <td>2019-06-30 21:49:34</td>\n",
       "      <td>91157.0</td>\n",
       "      <td>HALO Legends</td>\n",
       "      <td>Animation, Action, Adventure, Family, Sci-Fi</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>febf42d55f</td>\n",
       "      <td>d4fcb079ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671733</th>\n",
       "      <td>2019-06-30 22:00:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pacific Rim</td>\n",
       "      <td>Action, Adventure, Sci-Fi</td>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>7b15e5ada1</td>\n",
       "      <td>4a14a2cd5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671734</th>\n",
       "      <td>2019-06-30 22:04:23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ReMastered: The Two Killings of Sam Cooke</td>\n",
       "      <td>Documentary, Music</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>52d49c515a</td>\n",
       "      <td>0b8163ea4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671735</th>\n",
       "      <td>2019-06-30 22:35:24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chopsticks</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>0be62aac8b</td>\n",
       "      <td>5e5755d816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671736 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime  duration  \\\n",
       "0       2017-01-01 01:15:09       0.0   \n",
       "1       2017-01-01 13:56:02       0.0   \n",
       "2       2017-01-01 15:17:47   10530.0   \n",
       "3       2017-01-01 16:04:13      49.0   \n",
       "4       2017-01-01 19:16:37       0.0   \n",
       "...                     ...       ...   \n",
       "671731  2019-06-30 21:37:08     851.0   \n",
       "671732  2019-06-30 21:49:34   91157.0   \n",
       "671733  2019-06-30 22:00:44       0.0   \n",
       "671734  2019-06-30 22:04:23       0.0   \n",
       "671735  2019-06-30 22:35:24       0.0   \n",
       "\n",
       "                                            title  \\\n",
       "0              Angus, Thongs and Perfect Snogging   \n",
       "1                    The Curse of Sleeping Beauty   \n",
       "2                               London Has Fallen   \n",
       "3                                        Vendetta   \n",
       "4                 The SpongeBob SquarePants Movie   \n",
       "...                                           ...   \n",
       "671731        Oprah Presents When They See Us Now   \n",
       "671732                               HALO Legends   \n",
       "671733                                Pacific Rim   \n",
       "671734  ReMastered: The Two Killings of Sam Cooke   \n",
       "671735                                 Chopsticks   \n",
       "\n",
       "                                                   genres release_date  \\\n",
       "0                                  Comedy, Drama, Romance   2008-07-25   \n",
       "1                      Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
       "2                                        Action, Thriller   2016-03-04   \n",
       "3                                           Action, Drama   2015-06-12   \n",
       "4       Animation, Action, Adventure, Comedy, Family, ...   2004-11-19   \n",
       "...                                                   ...          ...   \n",
       "671731                                          Talk-Show   2019-06-12   \n",
       "671732       Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
       "671733                          Action, Adventure, Sci-Fi   2013-07-12   \n",
       "671734                                 Documentary, Music   2019-02-08   \n",
       "671735                                      Comedy, Drama   2019-05-31   \n",
       "\n",
       "          movie_id     user_id  \n",
       "0       26bd5987e8  1dea19f6fe  \n",
       "1       f26ed2675e  544dcbc510  \n",
       "2       f77e500e7a  7cbcc791bf  \n",
       "3       c74aec7673  ebf43c36b6  \n",
       "4       a80d6fc2aa  a57c992287  \n",
       "...            ...         ...  \n",
       "671731  43cd23f30f  57501964fd  \n",
       "671732  febf42d55f  d4fcb079ba  \n",
       "671733  7b15e5ada1  4a14a2cd5a  \n",
       "671734  52d49c515a  0b8163ea4b  \n",
       "671735  0be62aac8b  5e5755d816  \n",
       "\n",
       "[671736 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "original_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "It will be useful to convert both the the `datetime` and the `release_date` columns from a string to actual datetime format. We notice that some entries of `release_date` have value `NOT AVAILABLE`, we will have to convert them to NaT (Not a Time).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 01:15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angus, Thongs and Perfect Snogging</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>26bd5987e8</td>\n",
       "      <td>1dea19f6fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 13:56:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Curse of Sleeping Beauty</td>\n",
       "      <td>Fantasy, Horror, Mystery, Thriller</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>f26ed2675e</td>\n",
       "      <td>544dcbc510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 15:17:47</td>\n",
       "      <td>10530.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>7cbcc791bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 16:04:13</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Vendetta</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>c74aec7673</td>\n",
       "      <td>ebf43c36b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 19:16:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The SpongeBob SquarePants Movie</td>\n",
       "      <td>Animation, Action, Adventure, Comedy, Family, ...</td>\n",
       "      <td>2004-11-19</td>\n",
       "      <td>a80d6fc2aa</td>\n",
       "      <td>a57c992287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671731</th>\n",
       "      <td>2019-06-30 21:37:08</td>\n",
       "      <td>851.0</td>\n",
       "      <td>Oprah Presents When They See Us Now</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>43cd23f30f</td>\n",
       "      <td>57501964fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671732</th>\n",
       "      <td>2019-06-30 21:49:34</td>\n",
       "      <td>91157.0</td>\n",
       "      <td>HALO Legends</td>\n",
       "      <td>Animation, Action, Adventure, Family, Sci-Fi</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>febf42d55f</td>\n",
       "      <td>d4fcb079ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671733</th>\n",
       "      <td>2019-06-30 22:00:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pacific Rim</td>\n",
       "      <td>Action, Adventure, Sci-Fi</td>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>7b15e5ada1</td>\n",
       "      <td>4a14a2cd5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671734</th>\n",
       "      <td>2019-06-30 22:04:23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ReMastered: The Two Killings of Sam Cooke</td>\n",
       "      <td>Documentary, Music</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>52d49c515a</td>\n",
       "      <td>0b8163ea4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671735</th>\n",
       "      <td>2019-06-30 22:35:24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chopsticks</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>0be62aac8b</td>\n",
       "      <td>5e5755d816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671736 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  duration  \\\n",
       "0      2017-01-01 01:15:09       0.0   \n",
       "1      2017-01-01 13:56:02       0.0   \n",
       "2      2017-01-01 15:17:47   10530.0   \n",
       "3      2017-01-01 16:04:13      49.0   \n",
       "4      2017-01-01 19:16:37       0.0   \n",
       "...                    ...       ...   \n",
       "671731 2019-06-30 21:37:08     851.0   \n",
       "671732 2019-06-30 21:49:34   91157.0   \n",
       "671733 2019-06-30 22:00:44       0.0   \n",
       "671734 2019-06-30 22:04:23       0.0   \n",
       "671735 2019-06-30 22:35:24       0.0   \n",
       "\n",
       "                                            title  \\\n",
       "0              Angus, Thongs and Perfect Snogging   \n",
       "1                    The Curse of Sleeping Beauty   \n",
       "2                               London Has Fallen   \n",
       "3                                        Vendetta   \n",
       "4                 The SpongeBob SquarePants Movie   \n",
       "...                                           ...   \n",
       "671731        Oprah Presents When They See Us Now   \n",
       "671732                               HALO Legends   \n",
       "671733                                Pacific Rim   \n",
       "671734  ReMastered: The Two Killings of Sam Cooke   \n",
       "671735                                 Chopsticks   \n",
       "\n",
       "                                                   genres release_date  \\\n",
       "0                                  Comedy, Drama, Romance   2008-07-25   \n",
       "1                      Fantasy, Horror, Mystery, Thriller   2016-06-02   \n",
       "2                                        Action, Thriller   2016-03-04   \n",
       "3                                           Action, Drama   2015-06-12   \n",
       "4       Animation, Action, Adventure, Comedy, Family, ...   2004-11-19   \n",
       "...                                                   ...          ...   \n",
       "671731                                          Talk-Show   2019-06-12   \n",
       "671732       Animation, Action, Adventure, Family, Sci-Fi   2010-02-16   \n",
       "671733                          Action, Adventure, Sci-Fi   2013-07-12   \n",
       "671734                                 Documentary, Music   2019-02-08   \n",
       "671735                                      Comedy, Drama   2019-05-31   \n",
       "\n",
       "          movie_id     user_id  \n",
       "0       26bd5987e8  1dea19f6fe  \n",
       "1       f26ed2675e  544dcbc510  \n",
       "2       f77e500e7a  7cbcc791bf  \n",
       "3       c74aec7673  ebf43c36b6  \n",
       "4       a80d6fc2aa  a57c992287  \n",
       "...            ...         ...  \n",
       "671731  43cd23f30f  57501964fd  \n",
       "671732  febf42d55f  d4fcb079ba  \n",
       "671733  7b15e5ada1  4a14a2cd5a  \n",
       "671734  52d49c515a  0b8163ea4b  \n",
       "671735  0be62aac8b  5e5755d816  \n",
       "\n",
       "[671736 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.datetime = pd.to_datetime(original_dataset.datetime, errors='coerce')\n",
    "original_dataset.release_date = pd.to_datetime(original_dataset.release_date, errors='coerce')\n",
    "original_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 671736 entries, 0 to 671735\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   datetime      671736 non-null  datetime64[ns]\n",
      " 1   duration      671736 non-null  float64       \n",
      " 2   title         671736 non-null  object        \n",
      " 3   genres        671736 non-null  object        \n",
      " 4   release_date  641432 non-null  datetime64[ns]\n",
      " 5   movie_id      671736 non-null  object        \n",
      " 6   user_id       671736 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(1), object(4)\n",
      "memory usage: 35.9+ MB\n"
     ]
    }
   ],
   "source": [
    "original_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The Kaggle page of the dataset (https://www.kaggle.com/datasets/vodclickstream/netflix-audience-behaviour-uk-movies) give us informations about the `duration` column:\n",
    "\n",
    "`'duration' shows how long it was (in seconds) until that user clicked on another URL. A watch time of zero seconds means they visited the page but instantly clicked away.`\n",
    "\n",
    "It is already a float, we don't need to treat it any further.\n",
    "\n",
    "We can check the consistency of the dataset by checking if the same movie (i.e. all the entries with same `movie_id`) have the same characteristics (i.e. same `title`, `genres` and `release date`):\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate trough every movie\n",
    "for movie_id, group_data in original_dataset.groupby('movie_id'):\n",
    "    \n",
    "    # check if there is more than a title for the same movie\n",
    "    if group_data.title.unique().shape[0] != 1:\n",
    "        print(\"Movie\", movie_id, \"has more than a title!\")\n",
    "\n",
    "    # check if there is more than a genre list for the same movie\n",
    "    if group_data.genres.unique().shape[0] != 1:\n",
    "        print(\"Movie\", movie_id, \"has conflicting genres!\")\n",
    "\n",
    "    # check if there is more than a release date for the same movie\n",
    "    if group_data.release_date.unique().shape[0] != 1:\n",
    "        print(\"Movie\", movie_id, \"has conflicting release dates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Since the `genres` column is a string we have to convert it to a list.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 01:15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angus, Thongs and Perfect Snogging</td>\n",
       "      <td>[Comedy,  Drama,  Romance]</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>26bd5987e8</td>\n",
       "      <td>1dea19f6fe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 13:56:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Curse of Sleeping Beauty</td>\n",
       "      <td>[Fantasy,  Horror,  Mystery,  Thriller]</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>f26ed2675e</td>\n",
       "      <td>544dcbc510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 15:17:47</td>\n",
       "      <td>10530.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>[Action,  Thriller]</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>7cbcc791bf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 16:04:13</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Vendetta</td>\n",
       "      <td>[Action,  Drama]</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>c74aec7673</td>\n",
       "      <td>ebf43c36b6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 19:16:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The SpongeBob SquarePants Movie</td>\n",
       "      <td>[Animation,  Action,  Adventure,  Comedy,  Fam...</td>\n",
       "      <td>2004-11-19</td>\n",
       "      <td>a80d6fc2aa</td>\n",
       "      <td>a57c992287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671731</th>\n",
       "      <td>2019-06-30 21:37:08</td>\n",
       "      <td>851.0</td>\n",
       "      <td>Oprah Presents When They See Us Now</td>\n",
       "      <td>[Talk-Show]</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>43cd23f30f</td>\n",
       "      <td>57501964fd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671732</th>\n",
       "      <td>2019-06-30 21:49:34</td>\n",
       "      <td>91157.0</td>\n",
       "      <td>HALO Legends</td>\n",
       "      <td>[Animation,  Action,  Adventure,  Family,  Sci...</td>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>febf42d55f</td>\n",
       "      <td>d4fcb079ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671733</th>\n",
       "      <td>2019-06-30 22:00:44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pacific Rim</td>\n",
       "      <td>[Action,  Adventure,  Sci-Fi]</td>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>7b15e5ada1</td>\n",
       "      <td>4a14a2cd5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671734</th>\n",
       "      <td>2019-06-30 22:04:23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ReMastered: The Two Killings of Sam Cooke</td>\n",
       "      <td>[Documentary,  Music]</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>52d49c515a</td>\n",
       "      <td>0b8163ea4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671735</th>\n",
       "      <td>2019-06-30 22:35:24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chopsticks</td>\n",
       "      <td>[Comedy,  Drama]</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>0be62aac8b</td>\n",
       "      <td>5e5755d816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671736 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  duration  \\\n",
       "0      2017-01-01 01:15:09       0.0   \n",
       "1      2017-01-01 13:56:02       0.0   \n",
       "2      2017-01-01 15:17:47   10530.0   \n",
       "3      2017-01-01 16:04:13      49.0   \n",
       "4      2017-01-01 19:16:37       0.0   \n",
       "...                    ...       ...   \n",
       "671731 2019-06-30 21:37:08     851.0   \n",
       "671732 2019-06-30 21:49:34   91157.0   \n",
       "671733 2019-06-30 22:00:44       0.0   \n",
       "671734 2019-06-30 22:04:23       0.0   \n",
       "671735 2019-06-30 22:35:24       0.0   \n",
       "\n",
       "                                            title  \\\n",
       "0              Angus, Thongs and Perfect Snogging   \n",
       "1                    The Curse of Sleeping Beauty   \n",
       "2                               London Has Fallen   \n",
       "3                                        Vendetta   \n",
       "4                 The SpongeBob SquarePants Movie   \n",
       "...                                           ...   \n",
       "671731        Oprah Presents When They See Us Now   \n",
       "671732                               HALO Legends   \n",
       "671733                                Pacific Rim   \n",
       "671734  ReMastered: The Two Killings of Sam Cooke   \n",
       "671735                                 Chopsticks   \n",
       "\n",
       "                                                   genres release_date  \\\n",
       "0                              [Comedy,  Drama,  Romance]   2008-07-25   \n",
       "1                 [Fantasy,  Horror,  Mystery,  Thriller]   2016-06-02   \n",
       "2                                     [Action,  Thriller]   2016-03-04   \n",
       "3                                        [Action,  Drama]   2015-06-12   \n",
       "4       [Animation,  Action,  Adventure,  Comedy,  Fam...   2004-11-19   \n",
       "...                                                   ...          ...   \n",
       "671731                                        [Talk-Show]   2019-06-12   \n",
       "671732  [Animation,  Action,  Adventure,  Family,  Sci...   2010-02-16   \n",
       "671733                      [Action,  Adventure,  Sci-Fi]   2013-07-12   \n",
       "671734                              [Documentary,  Music]   2019-02-08   \n",
       "671735                                   [Comedy,  Drama]   2019-05-31   \n",
       "\n",
       "          movie_id     user_id  \n",
       "0       26bd5987e8  1dea19f6fe  \n",
       "1       f26ed2675e  544dcbc510  \n",
       "2       f77e500e7a  7cbcc791bf  \n",
       "3       c74aec7673  ebf43c36b6  \n",
       "4       a80d6fc2aa  a57c992287  \n",
       "...            ...         ...  \n",
       "671731  43cd23f30f  57501964fd  \n",
       "671732  febf42d55f  d4fcb079ba  \n",
       "671733  7b15e5ada1  4a14a2cd5a  \n",
       "671734  52d49c515a  0b8163ea4b  \n",
       "671735  0be62aac8b  5e5755d816  \n",
       "\n",
       "[671736 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.genres = original_dataset.genres.apply(lambda row: row.split(','))\n",
    "original_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We want to build a new dataset of user features extracted from the current one. We start by creating a dataframe containing only `user_id` and we populate it each time we build a new feature.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty user dataframe\n",
    "users_dataset_base = pd.DataFrame(original_dataset.user_id.unique(), columns = [\"user_id\"])\n",
    "\n",
    "\n",
    "'''\n",
    "    The first feature we want to build is:\n",
    "    **Favorite genre (i.e., the genre on which the user spent the most time)**\n",
    "    We can exploit the `explode` method of Pandas to get from each entry a new entry for each genre in the list:\n",
    "'''\n",
    "\n",
    "# create exploded dataframe\n",
    "exploded_dataset = original_dataset.explode(\"genres\")[[\"user_id\", \"genres\", \"duration\"]]\n",
    "\n",
    "# add together all values with same user_id and same genre\n",
    "exploded_dataset = exploded_dataset.groupby([\"user_id\", \"genres\"]).sum()\n",
    "\n",
    "# get most watched genre\n",
    "exploded_dataset = exploded_dataset.groupby(\"user_id\").idxmax()\n",
    "exploded_dataset.duration = exploded_dataset.duration.apply(lambda row: row[1])\n",
    "\n",
    "# rename column\n",
    "exploded_dataset = exploded_dataset.rename(columns={'duration': 'favorite_genre'})\n",
    "\n",
    "# merge into user dataset\n",
    "users_dataset_base = users_dataset_base.merge(exploded_dataset, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "'''\n",
    "    The second feature to extract is:\n",
    "    **Average click duration**\n",
    "    This is very fast as we have just to calculate the mean of the `duration` columns of every user:\n",
    "'''\n",
    "\n",
    "# get mean\n",
    "mean_dataset = original_dataset.groupby(\"user_id\").duration.mean().reset_index()\n",
    "\n",
    "# rename column\n",
    "mean_dataset = mean_dataset.rename(columns={'duration': 'mean_duration'})\n",
    "\n",
    "# merge into user dataset\n",
    "users_dataset_base = users_dataset_base.merge(mean_dataset)\n",
    "\n",
    "'''\n",
    "    The third feature feature is:\n",
    "    **Time of the day (Morning/Afternoon/Night) when the user spends the most time on the platform (the time spent is tracked through the duration of the clicks)**\n",
    "\n",
    "    We will use as delimitations between the three time parts:\n",
    "    - Morning: 6 to 14\n",
    "    - Afternoon: 14 to 20\n",
    "    - Night: 20 to 6\n",
    "'''\n",
    "\n",
    "# create working dataframe substituting the whole datetime with hour\n",
    "hours = original_dataset[[\"user_id\", \"datetime\", \"duration\"]].copy()\n",
    "hours.datetime = hours.datetime.dt.hour\n",
    "\n",
    "# cluster hours into three time periods\n",
    "hours.datetime = hours.datetime.apply(lambda x: 'morning' if 6 <= x < 14 else 'afternoon' if 14 <= x < 20 else 'night')\n",
    "\n",
    "# get most active time period for each user\n",
    "hours = hours.groupby([\"user_id\", \"datetime\"]).sum().groupby(\"user_id\").idxmax()\n",
    "hours.duration = hours.duration.apply(lambda row: row[1])\n",
    "\n",
    "# rename column\n",
    "hours = hours.rename(columns={'duration': 'favorite_time_day'})\n",
    "\n",
    "# merge into user dataset\n",
    "users_dataset_base = users_dataset_base.merge(hours, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "'''\n",
    "    The fourth feature is:\n",
    "    **Is the user an old movie lover, or is he into more recent stuff (content released after 2010)?**\n",
    "'''\n",
    "\n",
    "# convert all datetimes to only the year \n",
    "years = original_dataset[[\"user_id\", \"release_date\"]].copy()\n",
    "years.release_date = years.release_date.dt.year\n",
    "\n",
    "# check if film is old or not\n",
    "years[\"new\"] = years.release_date > 2010\n",
    "years[\"old\"] = years.release_date <= 2010\n",
    "\n",
    "# count for each user how many have release year > 2010 and how many not, use boolean value as new column\n",
    "user_oldnew = years.groupby(\"user_id\").old.sum() > years.groupby(\"user_id\").new.sum()\n",
    "\n",
    "# rename column\n",
    "user_oldnew.name = \"is_oldmovies_lover\"\n",
    "\n",
    "# merge into user dataset\n",
    "users_dataset_base = users_dataset_base.merge(user_oldnew, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "'''\n",
    "    The fifth feature is:\n",
    "    **Average time spent a day by the user (considering only the days he logs in)**\n",
    "'''\n",
    "\n",
    "# we can just take the mean_duration column and divide it by the number of different days the same user has in the dataset.\n",
    "\n",
    "# we count how many different days every user has logged in\n",
    "days = original_dataset[[\"user_id\", \"datetime\"]].copy()\n",
    "days[\"datetime\"] = days[\"datetime\"].dt.floor('D')\n",
    "days = days.groupby(\"user_id\").datetime.nunique()\n",
    "\n",
    "# we count the total duration per user\n",
    "sums = original_dataset.groupby(\"user_id\").duration.sum()\n",
    "\n",
    "# divide total duration by number of days\n",
    "average_per_day = sums / days\n",
    "\n",
    "# rename column\n",
    "average_per_day.name = \"duration_per_day\"\n",
    "\n",
    "# merge into user dataset\n",
    "users_dataset_base = users_dataset_base.merge(average_per_day, left_on = \"user_id\", right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>favorite_genre</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>favorite_time_day</th>\n",
       "      <th>is_oldmovies_lover</th>\n",
       "      <th>duration_per_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1dea19f6fe</td>\n",
       "      <td>Drama</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>night</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544dcbc510</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1553.750000</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>18645.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7cbcc791bf</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>4218.666667</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>8437.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebf43c36b6</td>\n",
       "      <td>Action</td>\n",
       "      <td>1883.533333</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>9417.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a57c992287</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3684.538462</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>7369.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161913</th>\n",
       "      <td>45414be0ec</td>\n",
       "      <td>Romance</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161914</th>\n",
       "      <td>783ec67e84</td>\n",
       "      <td>Drama</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161915</th>\n",
       "      <td>89c715f3a4</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161916</th>\n",
       "      <td>9207e1499b</td>\n",
       "      <td>Crime</td>\n",
       "      <td>42592.000000</td>\n",
       "      <td>night</td>\n",
       "      <td>False</td>\n",
       "      <td>42592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161917</th>\n",
       "      <td>57501964fd</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>851.000000</td>\n",
       "      <td>night</td>\n",
       "      <td>False</td>\n",
       "      <td>851.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161918 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id favorite_genre  mean_duration favorite_time_day  \\\n",
       "0       1dea19f6fe          Drama       0.000000             night   \n",
       "1       544dcbc510        Fantasy    1553.750000         afternoon   \n",
       "2       7cbcc791bf       Thriller    4218.666667         afternoon   \n",
       "3       ebf43c36b6         Action    1883.533333         afternoon   \n",
       "4       a57c992287          Drama    3684.538462         afternoon   \n",
       "...            ...            ...            ...               ...   \n",
       "161913  45414be0ec        Romance       0.000000         afternoon   \n",
       "161914  783ec67e84          Drama       0.000000         afternoon   \n",
       "161915  89c715f3a4      Adventure      -1.000000         afternoon   \n",
       "161916  9207e1499b          Crime   42592.000000             night   \n",
       "161917  57501964fd      Talk-Show     851.000000             night   \n",
       "\n",
       "        is_oldmovies_lover  duration_per_day  \n",
       "0                     True          0.000000  \n",
       "1                    False      18645.000000  \n",
       "2                    False       8437.333333  \n",
       "3                    False       9417.666667  \n",
       "4                    False       7369.076923  \n",
       "...                    ...               ...  \n",
       "161913               False          0.000000  \n",
       "161914                True          0.000000  \n",
       "161915               False         -1.000000  \n",
       "161916               False      42592.000000  \n",
       "161917               False        851.000000  \n",
       "\n",
       "[161918 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_dataset_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The additional features we propose are:\n",
    "\n",
    "- `watchtime`: the total watchtime of a certain user. It's the sum of all the durations.\n",
    "- `iterations`: the total number of iterations of a certain user. It's the number of rows related to that user.\n",
    "- `active_days`: the number of days the user has been active on the site. \n",
    "- `n_movies`: the number of unique movies watched by the user\n",
    "- `max_rewatches`: the maximum number of times the user has watched the same movie\n",
    "- `favorite_day`: the user favourite day of the week to watch movies. We search it by finding the day with the highest duration overall for that user\n",
    "- `favorite_month`: the user favourite month of the year to watch movies. We search it by finding the month with the highest duration overall for that user\n",
    "- `most_active_year`: the year the user has been most active on based on the duration.\n",
    "- `is_weekend_watcher`: if the user is a weekend watcher. We define a user \"weekend watcher\" if at least 50% of it's views are on saturday or sunday\n",
    "- `longest_iteration`: the longest iteration registered for the user. We search it by finding the max across all durations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty user dataframe\n",
    "users_dataset_extended = pd.DataFrame(original_dataset.user_id.unique(), columns = [\"user_id\"])\n",
    "\n",
    "# watchtime feature\n",
    "n_movies = original_dataset.groupby(\"user_id\").duration.sum()\n",
    "n_movies.name = \"total watchtime\"\n",
    "\n",
    "users_dataset_extended = users_dataset_extended.merge(n_movies, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "# number of iterations feature\n",
    "n_iterations = original_dataset.groupby(\"user_id\").size()\n",
    "n_iterations.name = \"iterations\"\n",
    "\n",
    "users_dataset_extended = users_dataset_extended.merge(n_iterations, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "# number of active days feature\n",
    "days_active = original_dataset[[\"user_id\", \"datetime\"]].copy()\n",
    "days_active[\"datetime\"] = days_active[\"datetime\"].dt.floor('D')\n",
    "days_active = days_active.groupby(\"user_id\").datetime.nunique()\n",
    "days_active.name = \"active_days\"\n",
    "\n",
    "users_dataset_extended = users_dataset_extended.merge(days_active, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "# number of unique movies feature\n",
    "n_movies = original_dataset.groupby(\"user_id\").movie_id.nunique()\n",
    "n_movies.name = \"n_movies\"\n",
    "users_dataset_extended = users_dataset_extended.merge(n_movies, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "# highest number of rewatches feature\n",
    "rewatch = original_dataset.groupby([\"user_id\", \"movie_id\"]).size().groupby(\"user_id\").max()\n",
    "rewatch.name = \"max_rewatches\"\n",
    "\n",
    "users_dataset_extended = users_dataset_extended.merge(rewatch, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "# favorite day of the week feature\n",
    "favourite_day = original_dataset[[\"user_id\", \"datetime\"]].copy()\n",
    "favourite_day.datetime = favourite_day.datetime.dt.dayofweek\n",
    "favourite_day = favourite_day.groupby([\"user_id\", \"datetime\"]).size().groupby(\"user_id\").idxmax().apply(lambda x: x[1])\n",
    "favourite_day.name = \"favorite_day\"\n",
    "\n",
    "users_dataset_extended = users_dataset_extended.merge(favourite_day, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "# favorite month of the year feature\n",
    "favourite_month = original_dataset[[\"user_id\", \"datetime\"]].copy()\n",
    "favourite_month.datetime = favourite_month.datetime.dt.month\n",
    "favourite_month = favourite_month.groupby([\"user_id\", \"datetime\"]).size().groupby(\"user_id\").idxmax().apply(lambda x: x[1])\n",
    "favourite_month.name = \"favorite_month\"\n",
    "\n",
    "users_dataset_extended = users_dataset_extended.merge(favourite_month, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "# most active year feature\n",
    "most_active_year = original_dataset[[\"user_id\", \"datetime\"]].copy()\n",
    "most_active_year.datetime = most_active_year.datetime.dt.year\n",
    "most_active_year = most_active_year.groupby([\"user_id\", \"datetime\"]).size().groupby(\"user_id\").idxmax().apply(lambda x: x[1])\n",
    "most_active_year.name = \"most_active_year\"\n",
    "\n",
    "users_dataset_extended = users_dataset_extended.merge(most_active_year, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "# weekend person feature\n",
    "def weekend_function(row):\n",
    "    row = row.droplevel(0)\n",
    "    row = row.reindex(range(7), fill_value=0)\n",
    "    return (row[5] + row[6]) > (row[0] + row[1] + row[2] + row[3] + row[4])\n",
    "\n",
    "weekend = original_dataset[[\"user_id\", \"datetime\"]].copy()\n",
    "weekend.datetime = weekend.datetime.dt.dayofweek\n",
    "weekend = weekend.groupby([\"user_id\", \"datetime\"]).size()\n",
    "weekend = weekend.groupby(\"user_id\").apply(weekend_function)\n",
    "weekend.name = \"is_weekend_user\"\n",
    "\n",
    "users_dataset_extended = users_dataset_extended.merge(weekend, left_on = \"user_id\", right_index = True)\n",
    "\n",
    "# longest iteration feature\n",
    "longest_iteration = original_dataset.groupby(\"user_id\").duration.max()\n",
    "longest_iteration.name = \"longest_iteration\"\n",
    "\n",
    "users_dataset_extended = users_dataset_extended.merge(longest_iteration, left_on = \"user_id\", right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>total watchtime</th>\n",
       "      <th>iterations</th>\n",
       "      <th>active_days</th>\n",
       "      <th>n_movies</th>\n",
       "      <th>max_rewatches</th>\n",
       "      <th>favorite_day</th>\n",
       "      <th>favorite_month</th>\n",
       "      <th>most_active_year</th>\n",
       "      <th>is_weekend_user</th>\n",
       "      <th>longest_iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1dea19f6fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544dcbc510</td>\n",
       "      <td>18645.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>10933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7cbcc791bf</td>\n",
       "      <td>25312.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>False</td>\n",
       "      <td>10530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebf43c36b6</td>\n",
       "      <td>28253.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>7524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a57c992287</td>\n",
       "      <td>95798.0</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>False</td>\n",
       "      <td>56338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161913</th>\n",
       "      <td>45414be0ec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161914</th>\n",
       "      <td>783ec67e84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161915</th>\n",
       "      <td>89c715f3a4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161916</th>\n",
       "      <td>9207e1499b</td>\n",
       "      <td>42592.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>42592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161917</th>\n",
       "      <td>57501964fd</td>\n",
       "      <td>851.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>851.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161918 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id  total watchtime  iterations  active_days  n_movies  \\\n",
       "0       1dea19f6fe              0.0           1            1         1   \n",
       "1       544dcbc510          18645.0          12            1         8   \n",
       "2       7cbcc791bf          25312.0           6            3         4   \n",
       "3       ebf43c36b6          28253.0          15            3        12   \n",
       "4       a57c992287          95798.0          26           13        22   \n",
       "...            ...              ...         ...          ...       ...   \n",
       "161913  45414be0ec              0.0           1            1         1   \n",
       "161914  783ec67e84              0.0           1            1         1   \n",
       "161915  89c715f3a4             -1.0           1            1         1   \n",
       "161916  9207e1499b          42592.0           1            1         1   \n",
       "161917  57501964fd            851.0           1            1         1   \n",
       "\n",
       "        max_rewatches  favorite_day  favorite_month  most_active_year  \\\n",
       "0                   1             6               1              2017   \n",
       "1                   3             6               1              2017   \n",
       "2                   3             6               1              2017   \n",
       "3                   2             6               1              2017   \n",
       "4                   3             0               1              2017   \n",
       "...               ...           ...             ...               ...   \n",
       "161913              1             6               6              2019   \n",
       "161914              1             6               6              2019   \n",
       "161915              1             6               6              2019   \n",
       "161916              1             6               6              2019   \n",
       "161917              1             6               6              2019   \n",
       "\n",
       "        is_weekend_user  longest_iteration  \n",
       "0                  True                0.0  \n",
       "1                  True            10933.0  \n",
       "2                 False            10530.0  \n",
       "3                  True             7524.0  \n",
       "4                 False            56338.0  \n",
       "...                 ...                ...  \n",
       "161913             True                0.0  \n",
       "161914             True                0.0  \n",
       "161915             True               -1.0  \n",
       "161916             True            42592.0  \n",
       "161917             True              851.0  \n",
       "\n",
       "[161918 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_dataset_extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "And finally we merge the two datasets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>favorite_genre</th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>favorite_time_day</th>\n",
       "      <th>is_oldmovies_lover</th>\n",
       "      <th>duration_per_day</th>\n",
       "      <th>total watchtime</th>\n",
       "      <th>iterations</th>\n",
       "      <th>active_days</th>\n",
       "      <th>n_movies</th>\n",
       "      <th>max_rewatches</th>\n",
       "      <th>favorite_day</th>\n",
       "      <th>favorite_month</th>\n",
       "      <th>most_active_year</th>\n",
       "      <th>is_weekend_user</th>\n",
       "      <th>longest_iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1dea19f6fe</td>\n",
       "      <td>Drama</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>night</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544dcbc510</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1553.750000</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>18645.000000</td>\n",
       "      <td>18645.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>10933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7cbcc791bf</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>4218.666667</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>8437.333333</td>\n",
       "      <td>25312.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>False</td>\n",
       "      <td>10530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebf43c36b6</td>\n",
       "      <td>Action</td>\n",
       "      <td>1883.533333</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>9417.666667</td>\n",
       "      <td>28253.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>7524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a57c992287</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3684.538462</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>7369.076923</td>\n",
       "      <td>95798.0</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>False</td>\n",
       "      <td>56338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161913</th>\n",
       "      <td>45414be0ec</td>\n",
       "      <td>Romance</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161914</th>\n",
       "      <td>783ec67e84</td>\n",
       "      <td>Drama</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161915</th>\n",
       "      <td>89c715f3a4</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>afternoon</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161916</th>\n",
       "      <td>9207e1499b</td>\n",
       "      <td>Crime</td>\n",
       "      <td>42592.000000</td>\n",
       "      <td>night</td>\n",
       "      <td>False</td>\n",
       "      <td>42592.000000</td>\n",
       "      <td>42592.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>42592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161917</th>\n",
       "      <td>57501964fd</td>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>851.000000</td>\n",
       "      <td>night</td>\n",
       "      <td>False</td>\n",
       "      <td>851.000000</td>\n",
       "      <td>851.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>851.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161918 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id favorite_genre  mean_duration favorite_time_day  \\\n",
       "0       1dea19f6fe          Drama       0.000000             night   \n",
       "1       544dcbc510        Fantasy    1553.750000         afternoon   \n",
       "2       7cbcc791bf       Thriller    4218.666667         afternoon   \n",
       "3       ebf43c36b6         Action    1883.533333         afternoon   \n",
       "4       a57c992287          Drama    3684.538462         afternoon   \n",
       "...            ...            ...            ...               ...   \n",
       "161913  45414be0ec        Romance       0.000000         afternoon   \n",
       "161914  783ec67e84          Drama       0.000000         afternoon   \n",
       "161915  89c715f3a4      Adventure      -1.000000         afternoon   \n",
       "161916  9207e1499b          Crime   42592.000000             night   \n",
       "161917  57501964fd      Talk-Show     851.000000             night   \n",
       "\n",
       "        is_oldmovies_lover  duration_per_day  total watchtime  iterations  \\\n",
       "0                     True          0.000000              0.0           1   \n",
       "1                    False      18645.000000          18645.0          12   \n",
       "2                    False       8437.333333          25312.0           6   \n",
       "3                    False       9417.666667          28253.0          15   \n",
       "4                    False       7369.076923          95798.0          26   \n",
       "...                    ...               ...              ...         ...   \n",
       "161913               False          0.000000              0.0           1   \n",
       "161914                True          0.000000              0.0           1   \n",
       "161915               False         -1.000000             -1.0           1   \n",
       "161916               False      42592.000000          42592.0           1   \n",
       "161917               False        851.000000            851.0           1   \n",
       "\n",
       "        active_days  n_movies  max_rewatches  favorite_day  favorite_month  \\\n",
       "0                 1         1              1             6               1   \n",
       "1                 1         8              3             6               1   \n",
       "2                 3         4              3             6               1   \n",
       "3                 3        12              2             6               1   \n",
       "4                13        22              3             0               1   \n",
       "...             ...       ...            ...           ...             ...   \n",
       "161913            1         1              1             6               6   \n",
       "161914            1         1              1             6               6   \n",
       "161915            1         1              1             6               6   \n",
       "161916            1         1              1             6               6   \n",
       "161917            1         1              1             6               6   \n",
       "\n",
       "        most_active_year  is_weekend_user  longest_iteration  \n",
       "0                   2017             True                0.0  \n",
       "1                   2017             True            10933.0  \n",
       "2                   2017            False            10530.0  \n",
       "3                   2017             True             7524.0  \n",
       "4                   2017            False            56338.0  \n",
       "...                  ...              ...                ...  \n",
       "161913              2019             True                0.0  \n",
       "161914              2019             True                0.0  \n",
       "161915              2019             True               -1.0  \n",
       "161916              2019             True            42592.0  \n",
       "161917              2019             True              851.0  \n",
       "\n",
       "[161918 rows x 16 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_dataset = users_dataset_base.merge(users_dataset_extended)\n",
    "users_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Choose your features (variables)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that you have plenty of features to work with now. So, it would be best to find a way to reduce the dimensionality (reduce the number of variables to work with). You can follow the subsequent directions to achieve it:\n",
    "\n",
    "1)  *To normalise or not to normalise? That's the question*. Sometimes, it is worth normalizing (scaling) the features. Explain if it is a good idea to perform any normalization method. If you think the normalization should be used, apply it to your data (look at the available normalization functions in the `scikit-learn` library).\n",
    "\n",
    "2)  Select **one** method for dimensionality reduction and apply it to your data. Some suggestions are Principal Component Analysis, Multiple Correspondence Analysis, Singular Value Decomposition, Factor Analysis for Mixed Data, Two-Steps clustering. Make sure that the method you choose applies to the features you have or modify your data to be able to use it. Explain why you chose that method and the limitations it may have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We will use as dimensionality reduction method the **Principal Component Analysis**. As the request make us choce only one dimensionality reduction method we will have to remove the two categorial features we have inside our dataset, `favorite_time_day` and `favorite_genre`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>is_oldmovies_lover</th>\n",
       "      <th>duration_per_day</th>\n",
       "      <th>total watchtime</th>\n",
       "      <th>iterations</th>\n",
       "      <th>active_days</th>\n",
       "      <th>n_movies</th>\n",
       "      <th>max_rewatches</th>\n",
       "      <th>favorite_day</th>\n",
       "      <th>favorite_month</th>\n",
       "      <th>most_active_year</th>\n",
       "      <th>is_weekend_user</th>\n",
       "      <th>longest_iteration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1dea19f6fe</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544dcbc510</th>\n",
       "      <td>1553.750000</td>\n",
       "      <td>False</td>\n",
       "      <td>18645.000000</td>\n",
       "      <td>18645.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>10933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7cbcc791bf</th>\n",
       "      <td>4218.666667</td>\n",
       "      <td>False</td>\n",
       "      <td>8437.333333</td>\n",
       "      <td>25312.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>False</td>\n",
       "      <td>10530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebf43c36b6</th>\n",
       "      <td>1883.533333</td>\n",
       "      <td>False</td>\n",
       "      <td>9417.666667</td>\n",
       "      <td>28253.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>True</td>\n",
       "      <td>7524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a57c992287</th>\n",
       "      <td>3684.538462</td>\n",
       "      <td>False</td>\n",
       "      <td>7369.076923</td>\n",
       "      <td>95798.0</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>False</td>\n",
       "      <td>56338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45414be0ec</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783ec67e84</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89c715f3a4</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9207e1499b</th>\n",
       "      <td>42592.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>42592.000000</td>\n",
       "      <td>42592.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>42592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57501964fd</th>\n",
       "      <td>851.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>851.000000</td>\n",
       "      <td>851.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>True</td>\n",
       "      <td>851.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161918 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean_duration  is_oldmovies_lover  duration_per_day  \\\n",
       "user_id                                                           \n",
       "1dea19f6fe       0.000000                True          0.000000   \n",
       "544dcbc510    1553.750000               False      18645.000000   \n",
       "7cbcc791bf    4218.666667               False       8437.333333   \n",
       "ebf43c36b6    1883.533333               False       9417.666667   \n",
       "a57c992287    3684.538462               False       7369.076923   \n",
       "...                   ...                 ...               ...   \n",
       "45414be0ec       0.000000               False          0.000000   \n",
       "783ec67e84       0.000000                True          0.000000   \n",
       "89c715f3a4      -1.000000               False         -1.000000   \n",
       "9207e1499b   42592.000000               False      42592.000000   \n",
       "57501964fd     851.000000               False        851.000000   \n",
       "\n",
       "            total watchtime  iterations  active_days  n_movies  max_rewatches  \\\n",
       "user_id                                                                         \n",
       "1dea19f6fe              0.0           1            1         1              1   \n",
       "544dcbc510          18645.0          12            1         8              3   \n",
       "7cbcc791bf          25312.0           6            3         4              3   \n",
       "ebf43c36b6          28253.0          15            3        12              2   \n",
       "a57c992287          95798.0          26           13        22              3   \n",
       "...                     ...         ...          ...       ...            ...   \n",
       "45414be0ec              0.0           1            1         1              1   \n",
       "783ec67e84              0.0           1            1         1              1   \n",
       "89c715f3a4             -1.0           1            1         1              1   \n",
       "9207e1499b          42592.0           1            1         1              1   \n",
       "57501964fd            851.0           1            1         1              1   \n",
       "\n",
       "            favorite_day  favorite_month  most_active_year  is_weekend_user  \\\n",
       "user_id                                                                       \n",
       "1dea19f6fe             6               1              2017             True   \n",
       "544dcbc510             6               1              2017             True   \n",
       "7cbcc791bf             6               1              2017            False   \n",
       "ebf43c36b6             6               1              2017             True   \n",
       "a57c992287             0               1              2017            False   \n",
       "...                  ...             ...               ...              ...   \n",
       "45414be0ec             6               6              2019             True   \n",
       "783ec67e84             6               6              2019             True   \n",
       "89c715f3a4             6               6              2019             True   \n",
       "9207e1499b             6               6              2019             True   \n",
       "57501964fd             6               6              2019             True   \n",
       "\n",
       "            longest_iteration  \n",
       "user_id                        \n",
       "1dea19f6fe                0.0  \n",
       "544dcbc510            10933.0  \n",
       "7cbcc791bf            10530.0  \n",
       "ebf43c36b6             7524.0  \n",
       "a57c992287            56338.0  \n",
       "...                       ...  \n",
       "45414be0ec                0.0  \n",
       "783ec67e84                0.0  \n",
       "89c715f3a4               -1.0  \n",
       "9207e1499b            42592.0  \n",
       "57501964fd              851.0  \n",
       "\n",
       "[161918 rows x 13 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_dataset.drop([\"favorite_genre\", \"favorite_time_day\"], axis = 1, inplace = True)\n",
    "users_dataset.set_index('user_id', inplace=True)\n",
    "users_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We  beleive that normalization is needed in our dataset because it makes the weight a certain feature has on the distance between points indipendent from the values that feature treats. If for  xample we have a certain arbitrary feature orders of magnitude greater than any other without normalization that would become the only significant component when calculating distance.\n",
    "\n",
    "We decided to use the standardization as normalizing function, to every feature we subtract the mean and divide by the standard deviation. This normalization fuction is available as `sklearn.preprocessing.StandardScaler`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>is_oldmovies_lover</th>\n",
       "      <th>duration_per_day</th>\n",
       "      <th>total watchtime</th>\n",
       "      <th>iterations</th>\n",
       "      <th>active_days</th>\n",
       "      <th>n_movies</th>\n",
       "      <th>max_rewatches</th>\n",
       "      <th>favorite_day</th>\n",
       "      <th>favorite_month</th>\n",
       "      <th>most_active_year</th>\n",
       "      <th>is_weekend_user</th>\n",
       "      <th>longest_iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.262460</td>\n",
       "      <td>2.007893</td>\n",
       "      <td>-0.288760</td>\n",
       "      <td>-0.373700</td>\n",
       "      <td>-0.480402</td>\n",
       "      <td>-0.539466</td>\n",
       "      <td>-0.491091</td>\n",
       "      <td>-0.515130</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>-1.462076</td>\n",
       "      <td>-1.171474</td>\n",
       "      <td>1.516133</td>\n",
       "      <td>-0.352242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.253090</td>\n",
       "      <td>-0.498034</td>\n",
       "      <td>-0.193209</td>\n",
       "      <td>-0.323529</td>\n",
       "      <td>1.197928</td>\n",
       "      <td>-0.539466</td>\n",
       "      <td>1.143182</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>-1.462076</td>\n",
       "      <td>-1.171474</td>\n",
       "      <td>1.516133</td>\n",
       "      <td>-0.315727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.237018</td>\n",
       "      <td>-0.498034</td>\n",
       "      <td>-0.245521</td>\n",
       "      <td>-0.305589</td>\n",
       "      <td>0.282475</td>\n",
       "      <td>0.171208</td>\n",
       "      <td>0.209312</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>-1.462076</td>\n",
       "      <td>-1.171474</td>\n",
       "      <td>-0.659573</td>\n",
       "      <td>-0.317073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.251101</td>\n",
       "      <td>-0.498034</td>\n",
       "      <td>-0.240497</td>\n",
       "      <td>-0.297676</td>\n",
       "      <td>1.655654</td>\n",
       "      <td>0.171208</td>\n",
       "      <td>2.077053</td>\n",
       "      <td>0.241605</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>-1.462076</td>\n",
       "      <td>-1.171474</td>\n",
       "      <td>1.516133</td>\n",
       "      <td>-0.327113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.240239</td>\n",
       "      <td>-0.498034</td>\n",
       "      <td>-0.250995</td>\n",
       "      <td>-0.115924</td>\n",
       "      <td>3.333984</td>\n",
       "      <td>3.724579</td>\n",
       "      <td>4.411729</td>\n",
       "      <td>0.998340</td>\n",
       "      <td>-1.453497</td>\n",
       "      <td>-1.462076</td>\n",
       "      <td>-1.171474</td>\n",
       "      <td>-0.659573</td>\n",
       "      <td>-0.164079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161913</th>\n",
       "      <td>-0.262460</td>\n",
       "      <td>-0.498034</td>\n",
       "      <td>-0.288760</td>\n",
       "      <td>-0.373700</td>\n",
       "      <td>-0.480402</td>\n",
       "      <td>-0.539466</td>\n",
       "      <td>-0.491091</td>\n",
       "      <td>-0.515130</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>1.489264</td>\n",
       "      <td>1.516133</td>\n",
       "      <td>-0.352242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161914</th>\n",
       "      <td>-0.262460</td>\n",
       "      <td>2.007893</td>\n",
       "      <td>-0.288760</td>\n",
       "      <td>-0.373700</td>\n",
       "      <td>-0.480402</td>\n",
       "      <td>-0.539466</td>\n",
       "      <td>-0.491091</td>\n",
       "      <td>-0.515130</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>1.489264</td>\n",
       "      <td>1.516133</td>\n",
       "      <td>-0.352242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161915</th>\n",
       "      <td>-0.262466</td>\n",
       "      <td>-0.498034</td>\n",
       "      <td>-0.288765</td>\n",
       "      <td>-0.373702</td>\n",
       "      <td>-0.480402</td>\n",
       "      <td>-0.539466</td>\n",
       "      <td>-0.491091</td>\n",
       "      <td>-0.515130</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>1.489264</td>\n",
       "      <td>1.516133</td>\n",
       "      <td>-0.352245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161916</th>\n",
       "      <td>-0.005593</td>\n",
       "      <td>-0.498034</td>\n",
       "      <td>-0.070487</td>\n",
       "      <td>-0.259092</td>\n",
       "      <td>-0.480402</td>\n",
       "      <td>-0.539466</td>\n",
       "      <td>-0.491091</td>\n",
       "      <td>-0.515130</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>1.489264</td>\n",
       "      <td>1.516133</td>\n",
       "      <td>-0.209989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161917</th>\n",
       "      <td>-0.257328</td>\n",
       "      <td>-0.498034</td>\n",
       "      <td>-0.284399</td>\n",
       "      <td>-0.371410</td>\n",
       "      <td>-0.480402</td>\n",
       "      <td>-0.539466</td>\n",
       "      <td>-0.491091</td>\n",
       "      <td>-0.515130</td>\n",
       "      <td>1.412119</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>1.489264</td>\n",
       "      <td>1.516133</td>\n",
       "      <td>-0.349400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161918 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_duration  is_oldmovies_lover  duration_per_day  total watchtime  \\\n",
       "0           -0.262460            2.007893         -0.288760        -0.373700   \n",
       "1           -0.253090           -0.498034         -0.193209        -0.323529   \n",
       "2           -0.237018           -0.498034         -0.245521        -0.305589   \n",
       "3           -0.251101           -0.498034         -0.240497        -0.297676   \n",
       "4           -0.240239           -0.498034         -0.250995        -0.115924   \n",
       "...               ...                 ...               ...              ...   \n",
       "161913      -0.262460           -0.498034         -0.288760        -0.373700   \n",
       "161914      -0.262460            2.007893         -0.288760        -0.373700   \n",
       "161915      -0.262466           -0.498034         -0.288765        -0.373702   \n",
       "161916      -0.005593           -0.498034         -0.070487        -0.259092   \n",
       "161917      -0.257328           -0.498034         -0.284399        -0.371410   \n",
       "\n",
       "        iterations  active_days  n_movies  max_rewatches  favorite_day  \\\n",
       "0        -0.480402    -0.539466 -0.491091      -0.515130      1.412119   \n",
       "1         1.197928    -0.539466  1.143182       0.998340      1.412119   \n",
       "2         0.282475     0.171208  0.209312       0.998340      1.412119   \n",
       "3         1.655654     0.171208  2.077053       0.241605      1.412119   \n",
       "4         3.333984     3.724579  4.411729       0.998340     -1.453497   \n",
       "...            ...          ...       ...            ...           ...   \n",
       "161913   -0.480402    -0.539466 -0.491091      -0.515130      1.412119   \n",
       "161914   -0.480402    -0.539466 -0.491091      -0.515130      1.412119   \n",
       "161915   -0.480402    -0.539466 -0.491091      -0.515130      1.412119   \n",
       "161916   -0.480402    -0.539466 -0.491091      -0.515130      1.412119   \n",
       "161917   -0.480402    -0.539466 -0.491091      -0.515130      1.412119   \n",
       "\n",
       "        favorite_month  most_active_year  is_weekend_user  longest_iteration  \n",
       "0            -1.462076         -1.171474         1.516133          -0.352242  \n",
       "1            -1.462076         -1.171474         1.516133          -0.315727  \n",
       "2            -1.462076         -1.171474        -0.659573          -0.317073  \n",
       "3            -1.462076         -1.171474         1.516133          -0.327113  \n",
       "4            -1.462076         -1.171474        -0.659573          -0.164079  \n",
       "...                ...               ...              ...                ...  \n",
       "161913        0.017497          1.489264         1.516133          -0.352242  \n",
       "161914        0.017497          1.489264         1.516133          -0.352242  \n",
       "161915        0.017497          1.489264         1.516133          -0.352245  \n",
       "161916        0.017497          1.489264         1.516133          -0.209989  \n",
       "161917        0.017497          1.489264         1.516133          -0.349400  \n",
       "\n",
       "[161918 rows x 13 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(users_dataset)\n",
    "scaled_users_dataset = pd.DataFrame(scaled_data, columns = users_dataset.columns)\n",
    "scaled_users_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "And we execute the principal component analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931745542116829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "model = PCA(n_components = 7)\n",
    "model.fit(scaled_users_dataset)\n",
    "print(model.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.220113</td>\n",
       "      <td>-0.594497</td>\n",
       "      <td>1.949122</td>\n",
       "      <td>-0.116857</td>\n",
       "      <td>1.921583</td>\n",
       "      <td>-0.856963</td>\n",
       "      <td>1.783640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.247025</td>\n",
       "      <td>1.259468</td>\n",
       "      <td>2.135746</td>\n",
       "      <td>0.322689</td>\n",
       "      <td>-0.322684</td>\n",
       "      <td>0.208478</td>\n",
       "      <td>1.994292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008452</td>\n",
       "      <td>0.908824</td>\n",
       "      <td>0.526405</td>\n",
       "      <td>0.295495</td>\n",
       "      <td>-0.259049</td>\n",
       "      <td>0.469726</td>\n",
       "      <td>1.997717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.736877</td>\n",
       "      <td>1.939737</td>\n",
       "      <td>2.185442</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>-0.498329</td>\n",
       "      <td>-0.946034</td>\n",
       "      <td>1.776856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.603943</td>\n",
       "      <td>5.448190</td>\n",
       "      <td>-1.069554</td>\n",
       "      <td>0.350815</td>\n",
       "      <td>-0.427975</td>\n",
       "      <td>-1.780785</td>\n",
       "      <td>1.451653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161913</th>\n",
       "      <td>-1.231643</td>\n",
       "      <td>-0.558274</td>\n",
       "      <td>1.993906</td>\n",
       "      <td>1.116751</td>\n",
       "      <td>-0.455734</td>\n",
       "      <td>0.054265</td>\n",
       "      <td>-0.962098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161914</th>\n",
       "      <td>-1.280490</td>\n",
       "      <td>-0.621236</td>\n",
       "      <td>2.047033</td>\n",
       "      <td>0.714025</td>\n",
       "      <td>1.978300</td>\n",
       "      <td>-0.351485</td>\n",
       "      <td>-1.098012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161915</th>\n",
       "      <td>-1.231649</td>\n",
       "      <td>-0.558269</td>\n",
       "      <td>1.993906</td>\n",
       "      <td>1.116751</td>\n",
       "      <td>-0.455734</td>\n",
       "      <td>0.054265</td>\n",
       "      <td>-0.962098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161916</th>\n",
       "      <td>-0.946532</td>\n",
       "      <td>-0.792869</td>\n",
       "      <td>1.995997</td>\n",
       "      <td>1.114713</td>\n",
       "      <td>-0.454810</td>\n",
       "      <td>0.059737</td>\n",
       "      <td>-0.965735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161917</th>\n",
       "      <td>-1.225946</td>\n",
       "      <td>-0.562961</td>\n",
       "      <td>1.993948</td>\n",
       "      <td>1.116710</td>\n",
       "      <td>-0.455715</td>\n",
       "      <td>0.054374</td>\n",
       "      <td>-0.962171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161918 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6\n",
       "0      -1.220113 -0.594497  1.949122 -0.116857  1.921583 -0.856963  1.783640\n",
       "1       0.247025  1.259468  2.135746  0.322689 -0.322684  0.208478  1.994292\n",
       "2       0.008452  0.908824  0.526405  0.295495 -0.259049  0.469726  1.997717\n",
       "3       0.736877  1.939737  2.185442  0.332031 -0.498329 -0.946034  1.776856\n",
       "4       3.603943  5.448190 -1.069554  0.350815 -0.427975 -1.780785  1.451653\n",
       "...          ...       ...       ...       ...       ...       ...       ...\n",
       "161913 -1.231643 -0.558274  1.993906  1.116751 -0.455734  0.054265 -0.962098\n",
       "161914 -1.280490 -0.621236  2.047033  0.714025  1.978300 -0.351485 -1.098012\n",
       "161915 -1.231649 -0.558269  1.993906  1.116751 -0.455734  0.054265 -0.962098\n",
       "161916 -0.946532 -0.792869  1.995997  1.114713 -0.454810  0.059737 -0.965735\n",
       "161917 -1.225946 -0.562961  1.993948  1.116710 -0.455715  0.054374 -0.962171\n",
       "\n",
       "[161918 rows x 7 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_users_dataset = pd.DataFrame(model.transform(scaled_users_dataset))\n",
    "pca_users_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "limitations of PCA: only linear dependence\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Clustering!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  Implement the K-means clustering algorithm (**not** ++: random initialization) using MapReduce. We ask you to write the algorithm from scratch following what you learned in class.\n",
    "\n",
    "2)  Find an optimal number of clusters. Use at least two different methods. If your algorithms provide diverse optimal K's, select one of them and explain why you chose it.\n",
    "\n",
    "3)  Run the algorithm on the data obtained from the dimensionality reduction.\n",
    "\n",
    "4)  Implement **K-means++** from scratch and explain the differences with the results you got earlier.\n",
    "\n",
    "5)  Ask ChatGPT to recommend other clustering algorithms and choose one. Explain your choice, then ask ChatGPT to implement it or use already implemented versions (e.g., the one provided in the scikit-learn library) and run it on your data. Explain the differences (if there are any) in the results. Which one is the best, in your opinion, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Analysing your results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are often encouraged to explain the main characteristics that your clusters have. The latter is called the *Characterizing Clusters* step. Thus, follow the next steps to do it:\n",
    "\n",
    "1)  Select 2-3 variables you think are relevant to identify the cluster of the customer. For example, Time_Day, Average Click Duration, etc.\n",
    "\n",
    "2)  Most of your selected variables will be numerical (continuous or discrete), then categorize them into four categories.\n",
    "\n",
    "3)  With the selected variables, perform pivot tables. On the horizontal axis, you will have the clusters, and on the vertical axis, you will have the categories of each variable. Notice that you have to do one pivot table per variable.\n",
    "\n",
    "4)  Calculate the percentage by column for each pivot table. The sum of each row (cluster) must be 100.\n",
    "\n",
    "5)  Interpret the results for each pivot table.\n",
    "\n",
    "6)  Use any known metrics to estimate clustering algorithm performance (how good are the clusters you found?). Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bonus Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remind you that we consider and grade the bonuses only if you complete the entire assignment.\n",
    "\n",
    "[Density-based clustering](https://wires.onlinelibrary.wiley.com/doi/epdf/10.1002/widm.30) identifies clusters as regions in the data space with high point density that are separated from other clusters by regions of low point density. The data points in the separating regions of low point density are typically considered noise or outliers. Typical algorithms that fall into this category are [OPTICS](https://dl.acm.org/doi/pdf/10.1145/304181.304187) and [DBSCAN](https://cdn.aaai.org/KDD/1996/KDD96-037.pdf).\n",
    "\n",
    "1)  Ask ChatGPT (or any other LLM tool) to list three algorithms for Density-Based Clustering. Choose one and use it on the same dataset you used in 2.3. Analyze your results: how different are they from the centroid-based version?\n",
    "\n",
    "__Note__: You can implement your algorithm from scratch or use the one implemented in the scikit-learn library; the choice is up to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Command Line Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another command line question to enjoy. We previously stated that using the command line tools is a skill that Data Scientists must master.\n",
    "\n",
    "In this question, you should use any command line tool that you know to answer the following questions using the same dataset that you have been using so far:\n",
    "  + What is the most-watched Netflix title?\n",
    "  + Report the average time between subsequent clicks on Netflix.com\n",
    "  + Provide the ID of the user that has spent the most time on Netflix\n",
    "    \n",
    "__Important note:__ You may work on this question in any environment (AWS, your PC command line, Jupyter notebook, etc.), but the final script must be placed in CommandLine.sh, which must be executable. Please run the script and include a __screenshot__ of the <ins>output</ins> in the notebook for evaluation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Algorithmic Question "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Federico studies in a demanding university where he has to take a certain number $N$ of exams to graduate,  but he is free to choose in which order he will take these exams. Federico is panicking since this university is not only one of the toughest in the world but also one of the weirdest. His final grade won't depend at all on the mark he gets in these courses: there's a precise evaluation system. \n",
    "\n",
    "He was given an initial personal score of $S$ when he enrolled, which changes every time he takes an exam: now comes the crazy part.\n",
    "He soon discovered that every of the $N$ exams he has to take is assigned a mark $p$. Once he has chosen an exam, his score becomes equal to the mark $p$, and at the same time, the scoring system changes:\n",
    "+ If he takes an \"easy\" exam (the score of the exam being less than his score), every other exam's mark is increased by the quantity $S - p$.\n",
    "+ If he takes a \"hard\" exam (the score of the exam is greater than his score), every other exam's mark is decreased by the quantity $p - S$.\n",
    "  \n",
    "So, for example, consider $S=8$ as the initial personal score. Federico must decide which exam he wants to take, being $[5,7,1]$ the marks list. If he takes the first one, being $5 < 8$ and $8 - 5 = 3$, the remaining list now becomes $[10,4]$, and his score is updated as $S = 5$.\n",
    "\n",
    "In this chaotic university where the only real exam seems to be choosing the best way to take exams, you are the poor student advisor who is facing a long queue of confused people who need some help. Federico is next in line,  and he comes up in turn with an inescapable question: he wants to know which is the highest score possible he could get. \n",
    "\n",
    "a) Fortunately, you have a computer app designed by a brilliant student. Federico wants you to show him the code which this app is based on\n",
    "because he wants to do paid counseling for other desperate students: in a *recursive* fashion, the helped helps the helpable.\n",
    "\n",
    "b) Federico is getting angry because he claims that your code is slow! Show him formally with a big-O notation that he is as crazy as this university! \n",
    "\n",
    "c) If, unfortunately, Federico is right in the grip of madness, he will threaten you to optimize the code through a different approach. \n",
    "You should end this theater of the absurd by any means! (And again, formally prove that you improved time complexity)\n",
    "\n",
    "d) Ask chatGPT for a third (optimized) implementation and analyze again its time complexity. Be careful (and crafty) in defining the prompt, and challenge the machine in this coding question!\n",
    "\n",
    "Here are some input/output examples (the first value is the initial personal score, and the second line contains the list of marks): \n",
    "\n",
    "__Input 1__\n",
    "```\n",
    "8\n",
    "5 7 1 \n",
    "```\n",
    "\n",
    "__Output 1__\n",
    "```\n",
    "11\n",
    "```\n",
    "\n",
    "__Input 2__\n",
    "```\n",
    "25\n",
    "18 24 21 32 27\n",
    "```\n",
    "\n",
    "__Output 2__\n",
    "```\n",
    "44\n",
    "```\n",
    "\n",
    "__Input 3__\n",
    "```\n",
    "30\n",
    "13 27 41 59 28 33 39 19 52 48 55 79\n",
    "```\n",
    "\n",
    "__Output 3__\n",
    "```\n",
    "205\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Fortunately, you have a computer app designed by a brilliant student. Federico wants you to show him the code which this app is based on\n",
    "because he wants to do paid counseling for other desperate students: in a *recursive* fashion, the helped helps the helpable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test1:\n",
      "11\n",
      "Test2:\n",
      "44\n",
      "Test3:\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def iterative_call(student_score, marks_list):\n",
    "    if len(marks_list) == 1:\n",
    "        return marks_list[0]\n",
    "    else:\n",
    "        best_score = 0\n",
    "        for i in range(len(marks_list)):\n",
    "            score = marks_list[i]\n",
    "            new_marks_list = np.concatenate([marks_list[:i], marks_list[i+1:]])\n",
    "            new_marks_list += (student_score - score)\n",
    "            new_score = iterative_call(score, new_marks_list)\n",
    "\n",
    "            best_score = max(new_score, best_score)\n",
    "        \n",
    "        return best_score\n",
    "\n",
    "def algorithmic_question(input_string):\n",
    "    # get first line of input\n",
    "    input_list = input_string.split(\"\\n\")\n",
    "    original_student_score = int(input_list[0])\n",
    "    original_marks_list = np.array(list(map(int, input_list[1].split(\" \"))))\n",
    "\n",
    "    best_score = iterative_call(original_student_score, original_marks_list)\n",
    "\n",
    "    print(best_score)\n",
    "\n",
    "input1 = \"8\\n5 7 1\"\n",
    "print(\"Test1:\")\n",
    "algorithmic_question(input1)\n",
    "\n",
    "input2 = \"25\\n18 24 21 32 27\"\n",
    "print(\"Test2:\")\n",
    "algorithmic_question(input2)\n",
    "\n",
    "input3 = \"30\\n13 27 41 59 28 33 39 19 52 48 55 79\"\n",
    "print(\"Test3:\")\n",
    "algorithmic_question(input3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Federico is getting angry because he claims that your code is slow! Show him formally with a big-O notation that he is as crazy as this university!**\n",
    "\n",
    "---\n",
    "\n",
    "**Time complexity:**\n",
    "\n",
    "We will analyze the computational time of the algorithm in Big-O notation in the `worst case scenario`.\n",
    "\n",
    "This algorithm explores all possible permutations of marks choices using recurive calls to avoid having to calculate the same parts parts more than once. Therefore to calculate the time complexity of the algorithm we have to find the cost of a `iterative_call` and how many calls the algorithm is gonna do. The number of iterative calls will be not only the number of permutations of `n` numbers, but we have also to consider \"intermediate\" operations. We have `n` ways to set the first mark, for each of those we have `n - 1` ways to set the second and so on...\n",
    "\n",
    "$n * (n - 1) * (n - 2) * ... * 2 * 1 = n!$\n",
    "\n",
    "To study the `iterative_call` function we will say that the current marks list has length `i`. In the worst case scenario this function is composed of a condition check on the length of the array (constant time) and a cycle trough the current elements of marks list (`i` repetitions) that for every cycle create a new array (linear cost `O(i)`), an update operation on the new array (linear cost `O(i)`), the next iterative call (that will have length `i - 1`) and a max operation (constant time). Ignoring the recursive call we can say that the function has cost `O(i)` with `i` length of the input.\n",
    "\n",
    "We can see that the real value of the iterative call is not important, as for the extreme case where `i = constant` the total cost of the algorithm will be:\n",
    "\n",
    "$n! * constant \\in O(n!)$\n",
    "\n",
    "And in the opposite extreme where `i = n` the total cost will be:\n",
    "\n",
    "$n! * n < n! * (n + 1) = (n + 1)! \\in O((n + 1)!) = O(n!)$\n",
    "\n",
    "And that is an unfeasable computational cost.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) If, unfortunately, Federico is right in the grip of madness, he will threaten you to optimize the code through a different approach. \n",
    "You should end this theater of the absurd by any means! (And again, formally prove that you improved time complexity)**\n",
    "\n",
    "---\n",
    "\n",
    "This new algorithm is based on the following observations on every permutation of the courses that yields the best output:\n",
    "* They are an alternation of decreases and increases\n",
    "* They start with a decrease and end with an increase\n",
    "* The only time there are two actions in the same side is when the number of marks is uneven\n",
    "\n",
    "Therefore to find the highest output value we can find the median, divide the marks list in two sets (one $\\le$ the median and one $>$) and  select them in alternating order.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test1:\n",
      "11\n",
      "Test2:\n",
      "44\n",
      "Test3:\n",
      "205\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def algorithmic_question(input_string):\n",
    "    # get first line of input\n",
    "    input_list = input_string.split(\"\\n\")\n",
    "    student_score = int(input_list[0])\n",
    "\n",
    "    # get marks list\n",
    "    marks_list = np.array(list(map(int, input_list[1].split(\" \"))))\n",
    "    marks_list.sort()\n",
    "\n",
    "    # if treat case uneven marks list\n",
    "    if len(marks_list) % 2 == 1:\n",
    "        # we will call those three lines \"update operation\"\n",
    "        new_score = marks_list[len(marks_list) // 2]\n",
    "        marks_list += (student_score - new_score)\n",
    "        student_score = new_score\n",
    "\n",
    "    # select them in alternating order\n",
    "    for i in range(len(marks_list) // 2):\n",
    "        new_score = marks_list[i]\n",
    "        marks_list += (student_score - new_score)\n",
    "        student_score = new_score\n",
    "\n",
    "        new_score = marks_list[-i -1]\n",
    "        marks_list += (student_score - new_score)\n",
    "        student_score = new_score\n",
    "    \n",
    "    print(student_score)\n",
    "\n",
    "input1 = \"8\\n5 7 1\"\n",
    "print(\"Test1:\")\n",
    "algorithmic_question(input1)\n",
    "\n",
    "input2 = \"25\\n18 24 21 32 27\"\n",
    "print(\"Test2:\")\n",
    "algorithmic_question(input2)\n",
    "\n",
    "input3 = \"30\\n13 27 41 59 28 33 39 19 52 48 55 79\"\n",
    "print(\"Test3:\")\n",
    "algorithmic_question(input3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Time complexity:**\n",
    "\n",
    "We will analyze the computational time of the algorithm in Big-O notation in the `worst case scenario`.\n",
    "\n",
    "We can see the algorithm as divided in three principal components with their cost proportional to the size number of marks in the input, that we will call `n`.\n",
    "\n",
    "* The first thing the algorithm do is read all the input, for which it takes time proportional to the size of the input, `O(n)`\n",
    "* After reading all the input the marks list is sorted to find the median, this will take `O(nlogn)` time\n",
    "* Finally for every mark the \"update operation\" is executed exactly one time. This update operation consist in reading the new mark score (costant time operation considering numpy arrays), updating every element in the marks list (which cost is linear) and finally updating the student score (constant time). Therefore the cost of each \"update operation\" is to be considered linear, `O(n)`. We can observe that deleting an element from the marks list after it is used will not help us reduce the computational cost, as also the delete operation as a linear cost or even updating only the unseen values, as the cost of `n` executions will always remain `O(n^2)`.\n",
    "\n",
    "The cost of the algorithm is therefore `O(n^2)` as the update operation will always be executed `n` times.\n",
    "\n",
    "We can observe that a study in the `average case scenario` would lead to a change of the computational cost in Big-O notation. As we are not interested in ordering the array but only find the median we could use a `quickselect` algorithm to find the median (average cost `O(n)`, worst case costs `O(n^2)`).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Ask chatGPT for a third (optimized) implementation and analyze again its time complexity. Be careful (and crafty) in defining the prompt, and challenge the machine in this coding question!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We asked Chat GPT 3.5 to write an algorithm using the following prompt:\n",
    "\n",
    "```\n",
    "Resolve the following problem with a python algorithm giving particular attention to code correctness and computational cost:\n",
    "[The proposed algorithm text, including the examples]\n",
    "```\n",
    "\n",
    "And the received output is:\n",
    "\n",
    "```\n",
    "This problem can be approached by iterating through the exams and determining whether an exam is \"easy\" or \"hard\" based on Federico's score and the exam's mark. Then, update the scores of the remaining exams accordingly. Here's a Python algorithm to solve this problem efficiently:\n",
    "\n",
    "def calculate_final_score(S, marks):\n",
    "    final_score = 0\n",
    "    for mark in marks:\n",
    "        if mark < S:\n",
    "            final_score += S - mark\n",
    "        else:\n",
    "            final_score += mark - S\n",
    "        # Update S for the next iteration\n",
    "        S = mark\n",
    "    return final_score\n",
    "\n",
    "# Test cases\n",
    "inputs = [\n",
    "    (8, [5, 7, 1]),\n",
    "    (25, [18, 24, 21, 32, 27]),\n",
    "    (30, [13, 27, 41, 59, 28, 33, 39, 19, 52, 48, 55, 79])\n",
    "]\n",
    "\n",
    "for S, marks in inputs:\n",
    "    result = calculate_final_score(S, marks)\n",
    "    print(result)\n",
    "```\n",
    "\n",
    "Which is both wrong and tries to mimick the recursive resolution of the problem. We therefore tried to rewrite the problem text in a more understandable way:\n",
    "\n",
    "```\n",
    "You are asked to write an optimized algorithm in python to solve the following problem: \n",
    "\n",
    "You start with a score \"S\" and a list of \"N\" other marks.  Everytime you take a score from the list (we will call it \"p\") you have to sum to every other exam remaining in the list the difference between S and p and then update S with the mark you extracted (S = p).\n",
    "\n",
    "You have to take all the elements from the list one by one in such a way that maximizes the value \"S\" has at the end of the execution.\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "[Same examples as before]\n",
    "```\n",
    "\n",
    "And the obtained response:\n",
    "\n",
    "```\n",
    "Sure, here's a Python solution to solve this problem using a greedy algorithm approach:\n",
    "\n",
    "def maximize_score(S, marks):\n",
    "    marks.sort(reverse=True)  # Sort marks in descending order\n",
    "    total = 0\n",
    "\n",
    "    for mark in marks:\n",
    "        total += S * len(marks)  # Update total by adding S times the number of remaining marks\n",
    "        S = mark  # Update S with the current mark\n",
    "\n",
    "    return total + S  # Add the final value of S to the total\n",
    "\n",
    "# Example inputs\n",
    "inputs = [\n",
    "    (8, [5, 7, 1]),\n",
    "    (25, [18, 24, 21, 32, 27]),\n",
    "    (30, [13, 27, 41, 59, 28, 33, 39, 19, 52, 48, 55, 79])\n",
    "]\n",
    "\n",
    "# Calculate and print outputs\n",
    "for i, (S, marks) in enumerate(inputs, 1):\n",
    "    result = maximize_score(S, marks)\n",
    "    print(f\"Output {i}: {result}\")\n",
    "\n",
    "\n",
    "Sure, here's a Python solution to solve this problem using a greedy algorithm approach:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "def maximize_score(S, marks):\n",
    "    marks.sort(reverse=True)  # Sort marks in descending order\n",
    "    total = 0\n",
    "\n",
    "    for mark in marks:\n",
    "        total += S * len(marks)  # Update total by adding S times the number of remaining marks\n",
    "        S = mark  # Update S with the current mark\n",
    "\n",
    "    return total + S  # Add the final value of S to the total\n",
    "\n",
    "# Example inputs\n",
    "inputs = [\n",
    "    (8, [5, 7, 1]),\n",
    "    (25, [18, 24, 21, 32, 27]),\n",
    "    (30, [13, 27, 41, 59, 28, 33, 39, 19, 52, 48, 55, 79])\n",
    "]\n",
    "\n",
    "# Calculate and print outputs\n",
    "for i, (S, marks) in enumerate(inputs, 1):\n",
    "    result = maximize_score(S, marks)\n",
    "    print(f\"Output {i}: {result}\")\n",
    "This code defines a maximize_score function that takes the initial score S and a list of marks as inputs. It sorts the marks in descending order and then iterates through each mark, updating the total score based on the described algorithm.\n",
    "\n",
    "The approach here is to sort the marks in descending order and for each mark, add the current score S multiplied by the number of remaining marks to the total. Finally, add the last value of S to the total and return it as the result.\n",
    "\n",
    "You can run this code with different inputs to get the corresponding outputs as described in your examples.\n",
    "```\n",
    "\n",
    "Which continues to be wrong and iterative. Therefore we tried to suggest him the reasoning behind the optimized solution:\n",
    "\n",
    "```\n",
    "You are asked to write an optimized algorithm in python to solve the following problem: \n",
    "\n",
    "You start with a score \"S\" and a list of \"N\" other marks.  Everytime you take a score from the list (we will call it \"p\") you have to update every exam remaining in the list by summing the difference between S and p to each value and then update S with the mark you extracted (S = p).\n",
    "\n",
    "You have to take all the elements from the list one by one in such a way that maximizes the value \"S\" has at the end of the execution.\n",
    "\n",
    "We have observed the following properties to all the permutations that yield the best possible output:\n",
    "* They are an alternation of values below and above the median\n",
    "* They start with a below and end with a value above\n",
    "* The only time there are two successive elements are from the same side is when the number of marks is uneven\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "[Same examples as before]\n",
    "```\n",
    "\n",
    "Which received as output:\n",
    "\n",
    "```\n",
    "This problem seems like a variation of a greedy algorithm. To approach this in Python, we can follow these steps:\n",
    "\n",
    "Sort the list of marks.\n",
    "Find the median.\n",
    "Create two lists: one for values below the median and one for values above it.\n",
    "Generate the alternating sequence starting with a value below the median and ending with a value above it.\n",
    "Update the score \"S\" and compute the maximum value.\n",
    "Here's a Python implementation:\n",
    "\n",
    "def maximize_score(S, marks):\n",
    "    marks.sort()  # Sort the list of marks\n",
    "    n = len(marks)\n",
    "    median = marks[n // 2] if n % 2 != 0 else (marks[n // 2 - 1] + marks[n // 2]) // 2\n",
    "\n",
    "    below_median = [mark for mark in marks if mark < median]\n",
    "    above_median = [mark for mark in marks if mark > median]\n",
    "\n",
    "    # Generating the alternating sequence\n",
    "    sequence = []\n",
    "    if n % 2 != 0:\n",
    "        while below_median and above_median:\n",
    "            sequence.append(below_median.pop())\n",
    "            sequence.append(above_median.pop())\n",
    "    else:\n",
    "        while below_median and above_median:\n",
    "            sequence.append(above_median.pop())\n",
    "            sequence.append(below_median.pop())\n",
    "\n",
    "    # Adding remaining elements if any\n",
    "    sequence.extend(below_median[::-1])\n",
    "    sequence.extend(above_median[::-1])\n",
    "\n",
    "    # Calculating the maximum value of S\n",
    "    for mark in sequence:\n",
    "        S += mark - S\n",
    "\n",
    "    return S\n",
    "\n",
    "# Test cases\n",
    "print(maximize_score(8, [5, 7, 1]))  # Output: 11\n",
    "print(maximize_score(25, [18, 24, 21, 32, 27]))  # Output: 44\n",
    "print(maximize_score(30, [13, 27, 41, 59, 28, 33, 39, 19, 52, 48, 55, 79]))  # Output: 205\n",
    "\n",
    "This Python code should solve the problem using the defined approach and provide the maximum value of \"S\" based on the given list of marks and initial score.\n",
    "```\n",
    "\n",
    "That is still wrong, but the approach is more similar to the optimized one.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
